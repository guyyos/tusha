{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set up the OpenAI API client\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Set up the model and prompt\n",
    "model_engine = \"text-davinci-003\"\n",
    "model_engine = 'gpt-3.5-turbo' # 4096 tokens limit for gpt-3.5-turbo-0301 (Both input and output tokens count) . see https://platform.openai.com/docs/guides/chat/introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 2020 World Series was played at Globe Life Field in Arlington, Texas.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "  \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "  try:\n",
    "      encoding = tiktoken.encoding_for_model(model)\n",
    "  except KeyError:\n",
    "      encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "  if model == \"gpt-3.5-turbo-0301\":  # note: future models may deviate from this\n",
    "      num_tokens = 0\n",
    "      for message in messages:\n",
    "          num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "          for key, value in message.items():\n",
    "              num_tokens += len(encoding.encode(value))\n",
    "              if key == \"name\":  # if there's a name, the role is omitted\n",
    "                  num_tokens += -1  # role is always required and always 1 token\n",
    "      num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "      return num_tokens\n",
    "  else:\n",
    "      raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\n",
    "  See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_response(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages)\n",
    "    return response,response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summer -> ice cream sales, summer -> drowning rate, ice cream sales -> drowning rate.'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"these are defined as my 'main options':\n",
    "        1. load a dataset file\n",
    "        2. save a model\n",
    "        3. compute or run the model\n",
    "        4. calculate statistics on the dataset\n",
    "        5. plot the features. create a graph.\n",
    "        5. I am not sure.\n",
    "        .\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": \"which option do I mean by the following (you should answer only with the option): 'upload the data \"},\n",
    "        {\"role\": \"user\", \"content\": \"which main option do I mean by the following (you should answer only with the option): 'plot zip code vs streeet\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"the dataset has these columns [a2s,gender,house_no,street_name,city,county,state,zip_cd,date_month,date_day], which columns are mentioned in these sentences:\n",
    "        sentence: plot a2s vs gender\n",
    "        columns: a2s,gender\n",
    "        sentence: plot house # vs zip code\n",
    "        columns:\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"the dataset has these columns [id,month,year,day,height]. \n",
    "        q: which columns are related to time?\n",
    "        a: month,year,day\n",
    "          the dataset has these columns [a2s,gender,house_no,street_name,city,county,state,zip_cd,date_month,date_day].\n",
    "        q: which columns are related to time?\"\"\"}\n",
    "\n",
    "    ]\n",
    "\n",
    "# main menu\n",
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a data scientist helper\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"these are defined as my 'main options':\n",
    "        * load a dataset file\n",
    "        * save a model\n",
    "        * compute or run the model\n",
    "        * calculate statistics on the dataset\n",
    "        * plot the features\n",
    "        * I am not sure, can you rephrase?\n",
    "        .\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": \n",
    "         \"\"\"which option do I mean by the following:\n",
    "         query: upload my data\n",
    "         answer: load a dataset file\n",
    "         query: make me coffee\n",
    "         answer: I am not sure, can you rephrase?\n",
    "         query: create a graph of weight vs height\n",
    "         answer: plot the features\n",
    "         query: calc mean and variance of x  \n",
    "         \"\"\"}\n",
    "    ]\n",
    "\n",
    "\n",
    "# rephrase option\n",
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a data scientist helper. Your name is Tusha. You are an expert at data science and bayesian statistics. \"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"who are you?\"\"\"}\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "# suggest causal network\n",
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a data scientist helper. Your name is Tusha. You are an expert at data science and bayesian statistics. \"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"suggest a causal network:\n",
    "        features: rain,season,wet,sprinkler,slippery\n",
    "        causal network: season->rain, season->sprinkler, sprinkler->wet, wet->slippery,rain->wet\n",
    "        features: age,diabetes,obesity,hypertension,gender,genetics,diet,alcohol\n",
    "        causal network:\n",
    "        \"\"\"}\n",
    "    ]\n",
    "\n",
    "# suggest causal network ||\n",
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a data scientist helper. Your name is Tusha. You are an expert at data science and bayesian statistics. \"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"suggest a causal network:\n",
    "        features: rain,season,wet,sprinkler,slippery\n",
    "        causal network: season->rain, season->sprinkler, sprinkler->wet, wet->slippery,rain->wet\n",
    "        features: burglary,recession,earthquake,alarm\n",
    "        causal network:\n",
    "        \"\"\"}\n",
    "    ]\n",
    "\n",
    "# suggest causal network ||\n",
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a data scientist helper. Your name is Tusha. You are an expert at data science and bayesian statistics. \"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"suggest a causal network:\n",
    "        features: rain,season,wet,sprinkler,slippery\n",
    "        causal network: season->rain, season->sprinkler, sprinkler->wet, wet->slippery,rain->wet\n",
    "        features: summer,ice cream sales, drowning rate\n",
    "        causal network:\n",
    "        \"\"\"}\n",
    "    ]\n",
    "\n",
    "num_tokens_from_messages(messages)\n",
    "\n",
    "response,response_content = chat_response(messages)\n",
    "response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'answer: calculate statistics on the dataset'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol->hypertension; gender,diet,hypertension->obesity; genetics,obesity,age->diabetes,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({'role':'assistant','content':response_content})\n",
    "# messages.append({'role':'user','content':'but there is no higher court than the supreme court. so can the parlimant contest an illegal decision of the supreme court?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer_chat_query:num_tokens = 129\n",
      "[\n",
      "    {\n",
      "        \"content\": \"You are a data scientist helper. Your name is Tusha. You are an expert at data science and bayesian statistics.\",\n",
      "        \"role\": \"system\"\n",
      "    },\n",
      "    {\n",
      "        \"content\": \"these are defined as my options:\\n            {main_option_str}\\n            .\",\n",
      "        \"role\": \"user\"\n",
      "    },\n",
      "    {\n",
      "        \"content\": \"complete the last option (if no option matches then just say 'not sure'. do not add explanations!):\\n            query: upload my data\\n            option: load a dataset file\\n            query: create a graph of weight vs height\\n            option: plot the features\\n            query: how many houses are in los angeles\\n            option:\\n            \",\n",
      "        \"role\": \"user\"\n",
      "    }\n",
      "]\n",
      "infer_chat_query: response_content: not sure., option = None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As an AI language model, I do not have access to real-time data. However, according to the United States Census Bureau's American Community Survey 5-Year Estimates conducted from 2015 to 2019, the estimated number of housing units in Los Angeles County is approximately 3.9 million. Please note that this is an estimate and the actual number of houses in Los Angeles may vary.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../tusha\")\n",
    "\n",
    "from chat_manager import infer_chat_query\n",
    "\n",
    "infer_chat_query('how many houses are in los angeles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[system]:You are a helpful assistant.\n",
      "\n",
      "[user]:Who is in charge of the military in Israel:  the prime minister or the supreme court?\n",
      "\n",
      "[assistant]:The Israeli Prime Minister is ultimately in charge of the military, as the head of the government and the commander-in-chief of the Israel Defense Forces. The Supreme Court does not have direct control over military operations, but it may rule on legal issues related to military policies and actions.\n",
      "\n",
      "[user]:so if the prime minister issues a command but the supreme court says its illegal. Who should the head of militray listen to?\n",
      "\n",
      "[assistant]:In such a scenario, the head of the military should follow the orders of the legal authority, which in this case would be the Supreme Court ruling. It is important to note that the Israeli military operates under the rule of law and is subject to the authority and oversight of the judicial system. The Prime Minister may change policies but they must also ensure that they are lawful and constitutional, and if there is a legal dispute, it falls on the judicial system to resolve it.\n",
      "\n",
      "[user]:but if the prime minister issues a legal command but the supreme court says its illegal. Who should the head of militray listen to?\n",
      "\n",
      "[assistant]:If the Prime Minister issues a legal command, but the Supreme Court rules it as illegal, the Head of Military should follow the orders of the legal authority, which would be the Supreme Court. The Israeli military operates under the rule of law and is subject to the authority and oversight of the judicial system. Therefore, the Head of Military has to obey the decision of the courts, which are the highest legal authority in Israel.\n",
      "\n",
      "[user]:but if the prime minister issues a legal command but the supreme court says that the changes in the law regarding the supreme court are illegal. Who should the head of militray listen to?\n",
      "\n",
      "[assistant]:If the Prime Minister issues a legal command that is based on changes in the law that the Supreme Court rules as illegal, then the Head of Military should obey the ruling of the Supreme Court. In this case, the Supreme Court would be the highest legal authority that interprets the law and determines whether the Prime Minister's command is lawful or not. It is important to note that the Head of Military has a responsibility to uphold the rule of law and must obey the decisions of the courts, which are the legal authority in Israel.\n",
      "\n",
      "[user]:if the parlimant changes the constitution, but the supreme court says that they cannot. Who should the head of militray listen to?\n",
      "\n",
      "[assistant]:If the Parliament changes the Constitution, but the Supreme Court says that they cannot, the Head of Military should obey the ruling of the Supreme Court. In Israel, the Supreme Court has the power of judicial review and can review and overturn laws that are unconstitutional, including constitutional amendments. Therefore, the Head of Military has a responsibility to uphold the rule of law and must obey the decisions of the courts, which are the highest legal authority in Israel.\n",
      "\n",
      "[user]:but that means that the supreme court is above the law. The parlimant cannot change the constitution. Therefore, its not a democracy but a rule of the supreme court.\n",
      "\n",
      "[assistant]:It is important to note that in a democracy, the judiciary serves as an important branch of government that is responsible for upholding the rule of law and ensuring that the actions of other branches of government comply with the Constitution. The Supreme Court in Israel is responsible for interpreting the Constitution and has the power of judicial review to strike down laws that are unconstitutional, including constitutional amendments. \n",
      "\n",
      "However, the Parliament in Israel also has the authority to amend the Constitution through a process defined in the Basic Laws. The Parliament is the elected representative body of the people and has the power to change the laws and the Constitution under certain conditions. \n",
      "\n",
      "The relationship between the judiciary and the Parliament is an important aspect of any democracy. A balance of power between branches of government is necessary to ensure that no single branch has too much power. It is the duty of the Supreme Court to uphold the rule of law and ensure that laws passed by the Parliament are constitutional. However, the Parliament also has the right to pass laws, including constitutional amendments, as long as they are consistent with the Constitution.\n",
      "\n",
      "[user]:can the parlimant add Basic Laws? if so, can the supreme court over rule them?\n",
      "\n",
      "[assistant]:Yes, in Israel, the Parliament (Knesset) can pass Basic Laws, which have the status of constitutional law. The Knesset has the power to amend or repeal Basic Laws, subject to certain procedural requirements defined in the laws themselves. \n",
      "\n",
      "As with any law passed by the Knesset, Basic Laws are subject to judicial review by the Supreme Court. The Court may review Basic Laws to determine their constitutionality and may strike down provisions that are inconsistent with the Basic Laws or other provisions of the Constitution. \n",
      "\n",
      "It is important to note that the Supreme Court's power of judicial review is not an absolute power but rather a power derived from the Constitution. The Court is responsible for upholding the Constitution, including the Basic Laws, and ensuring that the actions of other branches of government are consistent with the Constitution. However, the Knesset also has a role in the constitutional framework of Israel and has the authority to enact Basic Laws that are consistent with the Constitution.\n",
      "\n",
      "[user]:but if the supreme court illegaly overrules a law. is the law legal or illegal?\n",
      "\n",
      "[assistant]:If the Supreme Court overrules a law, it means that the law is no longer in effect and cannot be enforced. The Supreme Court has the power of judicial review, and so it can strike down laws that it deems to be unconstitutional. \n",
      "\n",
      "However, if the Supreme Court overrules a law in a way that is considered to be illegal, such as by going beyond its authority or by violating procedural requirements, there may be legal and political implications that need to be addressed. In such a case, the decision of the Supreme Court may be contested and reviewed by a higher court or through other legal and political means. \n",
      "\n",
      "Ultimately, the legality or illegality of the decision by the Supreme Court would depend on the circumstances of the case and the evaluation of the decision by the relevant legal and political authorities.\n",
      "\n",
      "[user]:but there is no higher court than the supreme court. so can the parlimant contest an illegal decision of the supreme court?\n",
      "\n",
      "[assistant]:In Israel, the Supreme Court is the highest judicial authority, and its decisions are final and binding. However, the Knesset, which is the body that represents the people in Israel, can introduce new laws to contest or override a decision by the Supreme Court. \n",
      "\n",
      "If the Parliament disagrees with the decision of the Supreme Court or considers it illegal, it can try to amend or repeal the law that gave the Court the authority to make such a decision. Alternatively, the Parliament can initiate a process to change the constitutional or Basic Laws, if applicable, to reduce the powers of the Supreme Court or to make it accountable to the other branches of government.\n",
      "\n",
      "However, in practice, changes to Basic Laws and constitutional amendments require a significant level of agreement and consensus among the lawmakers, and their adoption is not a trivial task. Additionally, the Supreme Court may review any new laws introduced by the Knesset, and may strike them down if they are unconstitutional.\n",
      "\n",
      "[user]:what do you think about the judicial reform? will it make Israel a dictatorship?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for msg in messages:\n",
    "    print(f\"[{msg['role']}]:{msg['content']}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI language model, I do not have personal opinions, but I can provide some context on the ongoing judicial reform in Israel. \\n\\nThe judicial reform proposed in Israel has led to a great deal of controversy and debate, with some critics arguing that it undermines the independence of the judiciary and consolidates more power in the government. Others argue that it is a necessary reform to address issues of transparency, accountability, and fairness in the justice system. \\n\\nIt is difficult to predict whether these changes would make Israel a dictatorship or not, as the definition of a dictatorship is complex and multifaceted. However, it is worth noting that judicial independence is an essential element of a democracy, and any efforts to undermine the independence of the judiciary could potentially be problematic for the functioning of democratic institutions in Israel.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_messages(messages)\n",
    "\n",
    "response,response_content = chat_response(messages)\n",
    "\n",
    "response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_messages(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-73kPPaa21KfnylfmSlhjOxcdCJqRf at 0x7fba7beddb70> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"In such a scenario, the head of the military should follow the orders of the legal authority, which in this case would be the Supreme Court ruling. It is important to note that the Israeli military operates under the rule of law and is subject to the authority and oversight of the judicial system. The Prime Minister may change policies but they must also ensure that they are lawful and constitutional, and if there is a legal dispute, it falls on the judicial system to resolve it.\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1681127735,\n",
       "  \"id\": \"chatcmpl-73kPPaa21KfnylfmSlhjOxcdCJqRf\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 94,\n",
       "    \"prompt_tokens\": 129,\n",
       "    \"total_tokens\": 223\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_completion(prompt):\n",
    "    completion = openai.Completion.create(\n",
    "        engine=model_engine,\n",
    "        prompt=prompt,\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "        )\n",
    "    return completion,completion.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcan \u001b[39m\u001b[39m{\u001b[39;00mcause\u001b[39m}\u001b[39;00m\u001b[39m increase \u001b[39m\u001b[39m{\u001b[39;00meffect\u001b[39m}\u001b[39;00m\u001b[39m. why?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39m# prompt = 'why?'\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[39m# Generate a response\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m completion,best_choice \u001b[39m=\u001b[39m text_completion(prompt)\n\u001b[1;32m      9\u001b[0m best_choice\n",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m, in \u001b[0;36mtext_completion\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtext_completion\u001b[39m(prompt):\n\u001b[0;32m----> 2\u001b[0m     completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      3\u001b[0m         engine\u001b[39m=\u001b[39;49mmodel_engine,\n\u001b[1;32m      4\u001b[0m         prompt\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m      5\u001b[0m         max_tokens\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m         n\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m         stop\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      8\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m         )\n\u001b[1;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m completion,completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\n",
      "File \u001b[0;32m~/miniconda3/envs/tusha-env/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda3/envs/tusha-env/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda3/envs/tusha-env/lib/python3.10/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/envs/tusha-env/lib/python3.10/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tusha-env/lib/python3.10/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?"
     ]
    }
   ],
   "source": [
    "cause = 'smoking'\n",
    "effect = 'cancer'\n",
    "prompt = f\"can {cause} increase {effect}.answer yes or no\"\n",
    "prompt = f\"can {cause} increase {effect}. why?\"\n",
    "# prompt = 'why?'\n",
    "\n",
    "# Generate a response\n",
    "completion,best_choice = text_completion(prompt)\n",
    "best_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nYour work is whatever you do for a living. Depending on your job, it could include anything from providing a service to creating a product.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = 'load my file'\n",
    "prompt = f'''I am a data scientist. A user is asking me the following: {user_query} . what is he asking for? answer one of the following options: \n",
    "1) run my experiment\n",
    "2) check the statistics of my dataset\n",
    "3) upload my dataset\n",
    "4) save my model '''\n",
    "\n",
    "user_query = 'calculate mean and variance'\n",
    "prompt = f''' Now he is asking : {user_query} . what is he asking for? answer one of the options I defined before.answer one of the following options: \n",
    "1) run my experiment\n",
    "2) check the statistics of my dataset\n",
    "3) upload my dataset\n",
    "4) save my model \n",
    "5) I'm not sure'''\n",
    "\n",
    "\n",
    "user_query = 'check the mean of xrf12'\n",
    "prompt = f''' the dataset has these features: ron,bhu,dd,ji12,xrf12,kop,FGT, and q1. Now he is asking : {user_query} . what is he asking for? answer one of the options I defined before.\n",
    "answer one of the following options (return the option number only): \n",
    "1) run my experiment\n",
    "2) check the statistics of my dataset\n",
    "3) upload my dataset\n",
    "4) save my model \n",
    "5) check something about a feature.\n",
    "6) I'm not sure'''\n",
    "\n",
    "\n",
    "user_query = 'check the mean of xrf12'\n",
    "prompt = f''' the dataset has these features: ron,bhu,dd,ji12,xrf12,kop,FGT, and q1. Now he is asking : {user_query} . which feature is he talking about? (feature name only)'''\n",
    "\n",
    "prompt = 'I am a data scientist.what do i do?'\n",
    "prompt = ' what is my work?'\n",
    "\n",
    "# prompt = 'why?'\n",
    "\n",
    "# Generate a response\n",
    "completion,best_choice = text_completion(prompt)\n",
    "best_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-73gcoxdeXEkiB6U6BuYq2EwrBRHex at 0x7fc4944e7970> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1681113190,\n",
       "  \"id\": \"cmpl-73gcoxdeXEkiB6U6BuYq2EwrBRHex\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 117,\n",
       "    \"total_tokens\": 117\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tusha-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03609ac9224b81167e8c0098cbfd7b8b92a04b17f1b1ebc11217760957456a9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
